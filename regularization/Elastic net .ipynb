{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "debbb3d9",
   "metadata": {},
   "source": [
    "##  THE MAIN DIFFERNCE BETWEEN RIDGE AND LASSO REGRESSION \n",
    "\n",
    "### We use ridge regression when we know that we will need all the columns in our dataset \n",
    "\n",
    "### Lasso regression is commonly used for feature selection when we have a high-dimensional dataset and suspect that only a subset of the features are important for predicting the target variable.\n",
    "\n",
    " By increasing the alpha parameter in Lasso regression, we can increase the strength of the L1 regularization penalty. This penalty encourages the coefficients of less important features to be pushed towards zero, effectively performing feature selection by shrinking the coefficients towards zero.\n",
    "\n",
    "As you mentioned, as we increase the alpha value in Lasso regression, the coefficients of less important features tend to become zero. This property of Lasso regression makes it useful for identifying and eliminating irrelevant features, leading to a more parsimonious and interpretable model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e367b9",
   "metadata": {},
   "source": [
    "### But what if we have a huge dataset  and we are not sure wheter to use ridge or lasso \n",
    "\n",
    "### we can use elastic net which is the combination of both ridge and lasso regression \n",
    " \n",
    "### The loss function used in Elastic Net is a combination of the L1 (Lasso) and L2 (Ridge) regularization penalties. Elastic Net adds both penalties to the ordinary least squares (OLS) loss function. The resulting loss function is as follows:\n",
    "\n",
    "\n",
    "\n",
    "loss = (1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * (l1_ratio * ||w||_1 + 0.5 * (1 - l1_ratio) * ||w||^2_2)\n",
    "\n",
    "### In this equation:\n",
    "\n",
    "* loss is the total loss function.\n",
    "\n",
    "* n_samples is the number of samples in the dataset.\n",
    "\n",
    "* y represents the target variable.\n",
    "\n",
    "* X represents the feature matrix.\n",
    "\n",
    "* w is the coefficient vector to be estimated.\n",
    "\n",
    "* alpha is the overall regularization strength parameter.\n",
    "\n",
    "* l1_ratio controls the mix between L1 and L2 regularization. It is a value between 0 and 1, where 0 corresponds to Ridge (L2) \n",
    "* regularization and 1 corresponds to Lasso (L1) regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "478b1221",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "import numpy as  np \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9a78123",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = load_diabetes(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17596633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 10)\n",
      "(442,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cb06cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test  , y_train , y_test = train_test_split(X , y , test_size = 0.2 ,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fb081f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51383940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'alpha': 0.001, 'l1_ratio': 0.7}\n",
      "R2 Score: 0.4611028760848328\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "param_grid = {'alpha': [0.001, 0.01, 0.1],\n",
    "              'l1_ratio': [0.5, 0.7, 0.9]}\n",
    "\n",
    "elastic_net = ElasticNet()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=elastic_net, param_grid=param_grid, scoring='r2')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a6f927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "100daysofmlkernel",
   "language": "python",
   "name": "100daysofmlkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
